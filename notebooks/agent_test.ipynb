{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentes en Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "# prompt = hub.pull(\"dialogue_agent\")\n",
    "# prompt.messages\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Respond only in Spanish.\"),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Desktop\\updt\\Programacion\\ia projects\\MultiAgent-SecondBrain-AI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.open_router import ChatOpenRouter\n",
    "\n",
    "model_name = 'openchat/openchat-7b:free'\n",
    "\n",
    "model = ChatOpenRouter(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Retorna el tamañño del string 'word'\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "tools = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hola!', 'output': 'Hola! ¿En qué puedo ayudarte hoy?'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Hola!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Quiero que me cuentes un chiste',\n",
       " 'output': '¿Sabes por qué los días son tan largos? Es porque el sol se levanta temprano. ¡Jajaja!'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Quiero que me cuentes un chiste\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadiendo memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hola, mi nombre es Christian!',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hola Christian, un placer conocerte.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Hola, mi nombre es Christian!\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Quiero que recuerdes mi nombre: Christian!'),\n",
       "  AIMessage(content='Hola Christian! En que puedo ayudarte?')],\n",
       " 'input': 'Cual es mi nombre?',\n",
       " 'output': 'Tu nombre es Christian. ¿En qué puedo ayudarte?'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"Quiero que recuerdes mi nombre: Christian!\"),\n",
    "            AIMessage(content=\"Hola Christian! En que puedo ayudarte?\"),\n",
    "        ],\n",
    "        \"input\": \"Cual es mi nombre?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hola! soy Christian',\n",
       " 'chat_history': [HumanMessage(content='Hola! soy Christian'),\n",
       "  AIMessage(content='Hola Christian! ¿En qué puedo ayudarte hoy?'),\n",
       "  HumanMessage(content='Cual es mi nombre?'),\n",
       "  AIMessage(content='Tu nombre es Christian.')],\n",
       " 'output': 'Hola Christian! ¿En qué puedo ayudarte hoy?'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"Hola! soy Christian\"},\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Cual es mi nombre?',\n",
       " 'chat_history': [HumanMessage(content='Hola! soy Christian'),\n",
       "  AIMessage(content='Hola Christian! ¿En qué puedo ayudarte hoy?'),\n",
       "  HumanMessage(content='Cual es mi nombre?'),\n",
       "  AIMessage(content='Tu nombre es Christian.'),\n",
       "  HumanMessage(content='Hola! soy Christian'),\n",
       "  AIMessage(content='Hola Christian! ¿En qué puedo ayudarte hoy?')],\n",
       " 'output': 'Tu nombre es Christian.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"Cual es mi nombre?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memoria para varios usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "\n",
    "\n",
    "def get_session_history(user_id: str, conversation_id: str):\n",
    "    return SQLChatMessageHistory(f\"{user_id}--{conversation_id}\", \"sqlite:///memory.db\")\n",
    "\n",
    "runnable = prompt | model\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=\"Conversation ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hola Christian, un gusto hablar contigo. ¿En qué puedo ayudarte hoy?', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 128, 'total_tokens': 153}, 'model_name': 'openchat/openchat-7b:free', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-22d702f3-46c6-4e81-aef6-6ce3a7829baa-0', usage_metadata={'input_tokens': 128, 'output_tokens': 25, 'total_tokens': 153})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"input\": \"Hola, mi nombre es Christian!\"},\n",
    "    config={\"configurable\": {\"user_id\": \"1\", \"conversation_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Tu nombre es Christian, como mencionaste al inicio. ¿En qué puedo ayudarte hoy?', response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 174, 'total_tokens': 200}, 'model_name': 'openchat/openchat-7b:free', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-44cc893a-fe92-4fb2-a6d5-cc1e8c587168-0', usage_metadata={'input_tokens': 174, 'output_tokens': 26, 'total_tokens': 200})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"input\": \"Cual es mi nombre?\"},\n",
    "    config={\"configurable\": {\"user_id\": \"1\", \"conversation_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Lo siento, aún no tengo información sobre su nombre. Si me proporciona más detalles, estaré encantado de ayudarle en lo que pueda.', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 101, 'total_tokens': 145}, 'model_name': 'openchat/openchat-7b:free', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-506db4c1-d826-4caf-afe8-fb8cc729bca4-0', usage_metadata={'input_tokens': 101, 'output_tokens': 44, 'total_tokens': 145})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"input\": \"Cual es mi nombre?\"},\n",
    "    config={\"configurable\": {\"user_id\": \"1\", \"conversation_id\": \"2\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.1.11-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.22 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from langgraph) (0.2.23)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (0.1.93)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\chris\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (24.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (8.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.22->langgraph) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\chris\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.2.22->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.2.22->langgraph) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\chris\\miniconda3\\envs\\py310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.2.22->langgraph) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2024.7.4)\n",
      "Downloading langgraph-0.1.11-py3-none-any.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.5 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 30.7/102.5 kB 1.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 30.7/102.5 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- 102.5/102.5 kB 738.0 kB/s eta 0:00:00\n",
      "Installing collected packages: langgraph\n",
      "Successfully installed langgraph-0.1.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_4876\\1525963175.py:6: LangGraphDeprecationWarning: Parameter 'messages_modifier' in function 'create_react_agent' is deprecated as of version 0.1.9 and will be removed in version 0.2.0. Use 'state_modifier' parameter instead.\n",
      "  agent = create_react_agent(model, tools, messages_modifier=system_message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "system_message = \"You are a helpful assistant. Respond only in Spanish.\"\n",
    "\n",
    "agent = create_react_agent(model, tools, messages_modifier=system_message)\n",
    "\n",
    "query = \"Hola, mi nombre es Christian!\"\n",
    "\n",
    "messages = agent.invoke({\"messages\": [(\"user\", query)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hola, mi nombre es Christian!', id='45efab64-bcde-4521-84eb-2851e02a3813'),\n",
       "  AIMessage(content='Hola Christian, un gusto hablar contigo. ¿En qué puedo ayudarte hoy?', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 43, 'total_tokens': 68}, 'model_name': 'openchat/openchat-7b:free', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6973bb6b-da9e-4803-9ab5-9cf471c75271-0', usage_metadata={'input_tokens': 43, 'output_tokens': 25, 'total_tokens': 68})]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadiendo Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_4876\\2446920177.py:8: LangGraphDeprecationWarning: Parameter 'messages_modifier' in function 'create_react_agent' is deprecated as of version 0.1.9 and will be removed in version 0.2.0. Use 'state_modifier' parameter instead.\n",
      "  agent = create_react_agent(model, tools, messages_modifier=system_message, checkpointer=memory)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "\n",
    "system_message = SystemMessage(content=system_message)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "agent = create_react_agent(model, tools, messages_modifier=system_message, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola Christian! Aquí tienes un chiste en español:\n",
      "\n",
      "¿Por qué no habla el zorro?\n",
      "Porque le cae la cola al abrir la boca.\n",
      "\n",
      "¡Espero que te haya hecho reír!\n",
      "---\n",
      "Sí, recuerdo que tu nombre es Christian. ¿En qué puedo ayudarte hoy?\n",
      "---\n",
      "Claro, aquí está la primera pregunta que hiciste:\n",
      "\n",
      "¿Podrías contarme un chiste?\n",
      "\n",
      "¡En serio! ¿En qué puedo ayudarte hoy? ¿Tienes alguna pregunta adicional o necesitas asistencia con algo en especial?\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    agent.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"user\", \"Hola, mi nombre es Christian! Me contarías un chiste?\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    agent.invoke({\"messages\": [(\"user\", \"Recuerdas mi nombre?\")]}, config)[\"messages\"][\n",
    "        -1\n",
    "    ].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    agent.invoke({\"messages\": [(\"user\", \"Me repites la primera pregunta que te hice?\")]}, config)[\n",
    "        \"messages\"\n",
    "    ][-1].content\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
